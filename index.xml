<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Wanting Xiang</title>
    <link>https://xiang-wt.github.io/</link>
      <atom:link href="https://xiang-wt.github.io/index.xml" rel="self" type="application/rss+xml" />
    <description>Wanting Xiang</description>
    <generator>Hugo Blox Builder (https://hugoblox.com)</generator><language>en-us</language><lastBuildDate>Tue, 29 Jul 2025 00:00:00 +0000</lastBuildDate>
    <image>
      <url>https://xiang-wt.github.io/media/icon_hu7729264130191091259.png</url>
      <title>Wanting Xiang</title>
      <link>https://xiang-wt.github.io/</link>
    </image>
    
    <item>
      <title>Example Talk</title>
      <link>https://xiang-wt.github.io/event/example/</link>
      <pubDate>Sat, 01 Jun 2030 13:00:00 +0000</pubDate>
      <guid>https://xiang-wt.github.io/event/example/</guid>
      <description>&lt;div class=&#34;flex px-4 py-3 mb-6 rounded-md bg-primary-100 dark:bg-primary-900&#34;&gt;
&lt;span class=&#34;pr-3 pt-1 text-primary-600 dark:text-primary-300&#34;&gt;
  &lt;svg height=&#34;24&#34; xmlns=&#34;http://www.w3.org/2000/svg&#34; viewBox=&#34;0 0 24 24&#34;&gt;&lt;path fill=&#34;none&#34; stroke=&#34;currentColor&#34; stroke-linecap=&#34;round&#34; stroke-linejoin=&#34;round&#34; stroke-width=&#34;1.5&#34; d=&#34;m11.25 11.25l.041-.02a.75.75 0 0 1 1.063.852l-.708 2.836a.75.75 0 0 0 1.063.853l.041-.021M21 12a9 9 0 1 1-18 0a9 9 0 0 1 18 0m-9-3.75h.008v.008H12z&#34;/&gt;&lt;/svg&gt;
&lt;/span&gt;
  &lt;span class=&#34;dark:text-neutral-300&#34;&gt;Click on the &lt;strong&gt;Slides&lt;/strong&gt; button above to view the built-in slides feature.&lt;/span&gt;
&lt;/div&gt;
&lt;p&gt;Slides can be added in a few ways:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Create&lt;/strong&gt; slides using Hugo Blox Builder&amp;rsquo;s &lt;a href=&#34;https://docs.hugoblox.com/reference/content-types/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;&lt;em&gt;Slides&lt;/em&gt;&lt;/a&gt; feature and link using &lt;code&gt;slides&lt;/code&gt; parameter in the front matter of the talk file&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Upload&lt;/strong&gt; an existing slide deck to &lt;code&gt;static/&lt;/code&gt; and link using &lt;code&gt;url_slides&lt;/code&gt; parameter in the front matter of the talk file&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Embed&lt;/strong&gt; your slides (e.g. Google Slides) or presentation video on this page using &lt;a href=&#34;https://docs.hugoblox.com/reference/markdown/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;shortcodes&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Further event details, including &lt;a href=&#34;https://docs.hugoblox.com/reference/markdown/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;page elements&lt;/a&gt; such as image galleries, can be added to the body of this page.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Projects</title>
      <link>https://xiang-wt.github.io/projects/</link>
      <pubDate>Tue, 29 Jul 2025 00:00:00 +0000</pubDate>
      <guid>https://xiang-wt.github.io/projects/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Microstate Graph Attention Network for Diagnosis and Severity Prediction of Tic Disorders from Electroencephalogram</title>
      <link>https://xiang-wt.github.io/publication/preprint/</link>
      <pubDate>Fri, 25 Jul 2025 00:00:00 +0000</pubDate>
      <guid>https://xiang-wt.github.io/publication/preprint/</guid>
      <description>&lt;p&gt;Microstate A shows enhanced connectivity centered on the parietal region, especially with widespread interactions involving P3. Microstate B presents strong connectivity centered on the left occipital and temporal regions, reflecting enhanced posterior sensory integration. Microstate C highlights increased connectivity in the inferior frontal , which may relate to executive control or speech regulation. Microstate D shows strong connectivity within the temporal lobes, suggesting potential involvement in perceptual, auditory, or semantic-related processing. 















&lt;figure  &gt;
  &lt;div class=&#34;flex justify-center	&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;https://xiang-wt.github.io/files/figure5.png&#34; alt=&#34;Model Interpretability&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;This work is driven by the results in my &lt;a href=&#34;https://xiang-wt.github.io/publication/conference-paper/&#34;&gt;previous paper&lt;/a&gt;.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>üéâ My first article has been published in IEEE</title>
      <link>https://xiang-wt.github.io/post/25.6.20/</link>
      <pubDate>Fri, 20 Jun 2025 00:00:00 +0000</pubDate>
      <guid>https://xiang-wt.github.io/post/25.6.20/</guid>
      <description>&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;flex justify-center	&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;https://xiang-wt.github.io/files/article.jpg&#34; alt=&#34;Article Photo&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;üéâ I‚Äôm thrilled to share that my &lt;strong&gt;first peer-reviewed academic article&lt;/strong&gt; has been officially published on &lt;strong&gt;IEEE Xplore&lt;/strong&gt;!&lt;/p&gt;
&lt;p&gt;üß† This work, titled &lt;em&gt;&amp;ldquo;Development and Validation of an Interpretable Machine Learning Model for Predicting Tic Disorders and Severity in Children Based on Electroencephalogram Data&amp;rdquo;&lt;/em&gt;, proposes a novel EEG-based framework  to assist the diagnosis and severity prediction of Tic Disorders (TD) in children.&lt;/p&gt;
&lt;p&gt;The model leverages interpretable machine learning techniques to extract clinically meaningful features from EEG signals, providing not only high classification performance but also neurophysiological insights aligned with known TD mechanisms.&lt;/p&gt;
&lt;p&gt;This milestone marks the beginning of my academic publishing journey, and I‚Äôm deeply grateful to my co-authors and mentors for their support and guidance throughout the process.&lt;/p&gt;
&lt;p&gt;üìö Published in: **IEEE Transactions on Neural Systems and Rehabilitation Engineering **&lt;br&gt;
üîó &lt;a href=&#34;https://doi.org/10.1109/TNSRE.2025.3579763&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Read the article on IEEE Xplore&lt;/a&gt; &lt;!-- Replace with actual DOI link --&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Development and Validation of an Interpretable Machine Learning Model for Predicting Tic Disorders and Severity in Children Based on Electroencephalogram Data</title>
      <link>https://xiang-wt.github.io/publication/conference-paper/</link>
      <pubDate>Fri, 20 Jun 2025 00:00:00 +0000</pubDate>
      <guid>https://xiang-wt.github.io/publication/conference-paper/</guid>
      <description>&lt;p&gt;We proposed a novel EEG-based two-stage diagnosis framework for Tic Disorders (TD) that aligns with clinical processes by first identifying disease presence and then assessing severity. To address segment-level inconsistency across subjects, we developed an individual-based feature-weighted integration module that aggregates EEG segments into robust subject-level representations. Additionally, we introduced a SHAP-driven Feature Selection and Weighting (SFSW) strategy that goes beyond binary selection by assigning interpretable weights to features, enabling fine-grained control and improved model performance. Together, these innovations enhanced individual-level prediction accuracy, model generalizability, and interpretability in real clinical contexts.&lt;/p&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;flex justify-center	&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;https://xiang-wt.github.io/files/figure2.png&#34; alt=&#34;Model overview&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;Our interpretability analysis revealed that abnormalities in the Œ≤ band of the P3 channel and the Œ≥ band of the C3 channel were key EEG biomarkers distinguishing TD from healthy controls, consistent with prior neurophysiological studies. Statistical features such as kurtosis and Hjorth complexity also contributed significantly, reflecting abnormal neuronal synchrony and signal irregularity. Spatially, central and parietal regions‚Äîparticularly the motor cortex‚Äîwere strongly associated with TD-related motor dysfunction. Additionally, age emerged as an important factor, supporting the neurodevelopmental nature of TD and its evolving EEG patterns with maturation.&lt;/p&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;flex justify-center	&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;https://xiang-wt.github.io/files/figure4.png&#34; alt=&#34;Model Interpretability&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>üì∏ Attended the 7th International Conference on Mathematical Biology</title>
      <link>https://xiang-wt.github.io/post/24.6.28/</link>
      <pubDate>Fri, 28 Jun 2024 00:00:00 +0000</pubDate>
      <guid>https://xiang-wt.github.io/post/24.6.28/</guid>
      <description>&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;flex justify-center	&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;https://xiang-wt.github.io/files/forum-2024.jpg&#34; alt=&#34;Forum Photo&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;From June 24 to 28, 2024, I attended the &lt;strong&gt;7th International Conference on Mathematical Biology&lt;/strong&gt;, held in &lt;strong&gt;Xi‚Äôan&lt;/strong&gt;, China.&lt;/p&gt;
&lt;p&gt;üìç This international event brought together leading experts in mathematical modeling, infectious disease dynamics, and systems biology.&lt;/p&gt;
&lt;p&gt;üì∏ &lt;strong&gt;I was truly honored to meet and take a photo with Professor Zhien Ma&lt;/strong&gt;, a pioneer in the field whose work greatly inspires me.&lt;/p&gt;
&lt;p&gt;üå± This experience strengthened my determination to pursue academic research, and I aspire to become a scholar with real impact in the future.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>üß† Attended the Brain Disorder Diagnosis Forum</title>
      <link>https://xiang-wt.github.io/post/23.11.4/</link>
      <pubDate>Sat, 04 Nov 2023 00:00:00 +0000</pubDate>
      <guid>https://xiang-wt.github.io/post/23.11.4/</guid>
      <description>&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;flex justify-center	&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;https://xiang-wt.github.io/files/forum-2023.jpg&#34; alt=&#34;Forum Photo&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;On November 4, 2023, I attended the &lt;strong&gt;Frontier Forum on Mathematical Methods for Intelligent Diagnosis and Treatment of Infant Brain Disorders&lt;/strong&gt;, organized by the Northwest Center of the National Tianyuan Mathematic.&lt;/p&gt;
&lt;p&gt;üìç The event brought together scholars from across disciplines, including clinical experts from the &lt;strong&gt;PLA General Hospital (301 Hospital)&lt;/strong&gt;, who shared insights on early diagnosis, modeling techniques, and real-world applications.&lt;/p&gt;
&lt;p&gt;üß† I was particularly inspired by the talks given by clinicians from 301 Hospital. Their interdisciplinary work combining medicine and mathematics sparked my passion for studying brain disorders from a computational perspective.&lt;/p&gt;
&lt;p&gt;üí° This forum further strengthened my motivation to explore neurological diseases through mathematical modeling and intelligent diagnostic frameworks.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Experience</title>
      <link>https://xiang-wt.github.io/experience/</link>
      <pubDate>Tue, 24 Oct 2023 00:00:00 +0000</pubDate>
      <guid>https://xiang-wt.github.io/experience/</guid>
      <description></description>
    </item>
    
    <item>
      <title>‚ú® Grateful to Keep Being a Student</title>
      <link>https://xiang-wt.github.io/post/23.9.3/</link>
      <pubDate>Sun, 03 Sep 2023 00:00:00 +0000</pubDate>
      <guid>https://xiang-wt.github.io/post/23.9.3/</guid>
      <description>&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;flex justify-center	&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;https://xiang-wt.github.io/files/enroll.jpg&#34; alt=&#34;Enroll Photo&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;üëã In 2023, I was honored to attend the opening ceremony for graduate students at Xi&amp;rsquo;an Jiaotong University.&lt;/p&gt;
&lt;p&gt;Standing in front of the Hanying Building, I deeply appreciated the opportunity to continue my journey as a student.&lt;/p&gt;
&lt;p&gt;‚ù§Ô∏è It&amp;rsquo;s a blessing to keep learning ‚Äî to remain curious, humble, and committed to growth.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>üéì Bachelor&#39;s Graduation from Zhengzhou University</title>
      <link>https://xiang-wt.github.io/post/23.6.28/</link>
      <pubDate>Wed, 28 Jun 2023 00:00:00 +0000</pubDate>
      <guid>https://xiang-wt.github.io/post/23.6.28/</guid>
      <description>&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;flex justify-center	&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;https://xiang-wt.github.io/files/graduate.jpg&#34; alt=&#34;Campus Photo&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;üéì I‚Äôm happy to share that I‚Äôve officially graduated from the School of Business at Zhengzhou University, majoring in Economic Statistics.&lt;/p&gt;
&lt;p&gt;üìÖ Over the past four years, I‚Äôve gone through many challenges, participated in various competitions üèÜ, and constantly pushed myself beyond my comfort zone üí™. These experiences shaped who I am today.&lt;/p&gt;
&lt;p&gt;üôè Looking back, I‚Äôm deeply grateful‚Äînot only to my teachers, classmates, and family‚Äîbut also to myself. It was my continuous effort and resilience that brought me to this milestone.&lt;/p&gt;
&lt;p&gt;üöÄ I look forward to the next chapter of growth and discovery!&lt;/p&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;flex justify-center	&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;https://xiang-wt.github.io/files/graduate-me.jpg&#34; alt=&#34;Campus Photo&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;‚ú® I hope my future self will shine as brightly as the sun ‚Äî full of passion, confidence, and warmth. ‚òÄÔ∏è&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Automatic detection method of pharyngeal region based on convolutional neural network</title>
      <link>https://xiang-wt.github.io/project/pandas/</link>
      <pubDate>Fri, 02 Jun 2023 00:00:00 +0000</pubDate>
      <guid>https://xiang-wt.github.io/project/pandas/</guid>
      <description>&lt;h2 id=&#34;-abstract&#34;&gt;üîç Abstract&lt;/h2&gt;
&lt;p&gt;This project proposes a CNN-based method for automatic detection of the pharyngeal region, focusing on key structures such as tonsils and the uvula. I independently reproduced the full &lt;strong&gt;Mask R-CNN&lt;/strong&gt; model using PyTorch, with a ResNet50 + FPN backbone.&lt;/p&gt;
&lt;p&gt;The training dataset of 585 oral images was &lt;strong&gt;collected and labeled&lt;/strong&gt; to define five distinct regions. Through extensive experiments, I performed &lt;strong&gt;multiple rounds of hyperparameter tuning&lt;/strong&gt; (learning rate, batch size, anchor ratios) to improve model accuracy and generalization.&lt;/p&gt;
&lt;p&gt;The final model achieved &lt;strong&gt;0.99 mAP&lt;/strong&gt; at IoU=0.5 and performed robustly on 100 unseen images with an average segmentation accuracy of &lt;strong&gt;92.1%&lt;/strong&gt;. This work demonstrates strong potential in supporting intelligent swab sampling in clinical environments.
















&lt;figure  &gt;
  &lt;div class=&#34;flex justify-center	&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;https://xiang-wt.github.io/files/loss.jpg&#34; alt=&#34;Loss&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;h2 id=&#34;-key-contributions&#34;&gt;üí° Key Contributions&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Independently reproduced the full Mask R-CNN architecture using PyTorch.&lt;/li&gt;
&lt;li&gt;Collected and labeled 585 oral images.&lt;/li&gt;
&lt;li&gt;Conducted iterative hyperparameter tuning to optimize performance.&lt;/li&gt;
&lt;li&gt;Achieved high segmentation precision and strong generalization to new samples.&lt;/li&gt;
&lt;li&gt;Combining engineering implementation with medical scene requirements&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;-project-period&#34;&gt;üìÖ Project Period&lt;/h2&gt;
&lt;p&gt;December 2022 ‚Äì June 2023&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>‚úÖ Internship at NIO Completed</title>
      <link>https://xiang-wt.github.io/post/23.5.31/</link>
      <pubDate>Wed, 31 May 2023 00:00:00 +0000</pubDate>
      <guid>https://xiang-wt.github.io/post/23.5.31/</guid>
      <description>&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;flex justify-center	&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;https://xiang-wt.github.io/files/iner.jpg&#34; alt=&#34;Inter Photo&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;üéâ My internship at &lt;strong&gt;NIO&lt;/strong&gt; has officially come to an end.&lt;/p&gt;
&lt;p&gt;During this unforgettable journey, I acquired practical skills in service operations, improved my communication and problem-solving abilities, and gained a real sense of what it&amp;rsquo;s like to work in a fast-paced, innovative company.&lt;/p&gt;
&lt;p&gt;üíº More than just learning about work, I also experienced the rhythms of professional life ‚Äî from teamwork and deadlines to self-discipline and responsibility.&lt;/p&gt;
&lt;p&gt;üôè I&amp;rsquo;m truly grateful for every mentor, colleague, and challenge that helped shape this growth. I leave NIO with confidence, appreciation, and a renewed drive for the future.&lt;/p&gt;
&lt;p&gt;üåü Onward to the next chapter!&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>üèÜ National Second Prize - Challenge Cup</title>
      <link>https://xiang-wt.github.io/post/22.3.28/</link>
      <pubDate>Mon, 28 Mar 2022 00:00:00 +0000</pubDate>
      <guid>https://xiang-wt.github.io/post/22.3.28/</guid>
      <description>&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;flex justify-center	&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;https://xiang-wt.github.io/files/tiaozhan.jpg&#34; alt=&#34;Tiaozhan Photo&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;üéâ I was honored to participate in the 17th &amp;ldquo;Challenge Cup&amp;rdquo; National Undergraduate Extracurricular Academic and Technological Works Competition.&lt;/p&gt;
&lt;p&gt;Our team was awarded the &lt;strong&gt;National Second Prize&lt;/strong&gt;, which was a great recognition of our efforts and collaboration. This experience not only tested our academic skills but also strengthened our teamwork and creativity.&lt;/p&gt;
&lt;p&gt;üìç This photo was taken at the competition venue, capturing a proud moment of shared achievement.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Survey on the cognition and willingness to pay for ecological compensation in the Yellow River Basin</title>
      <link>https://xiang-wt.github.io/project/pytorch/</link>
      <pubDate>Mon, 28 Mar 2022 00:00:00 +0000</pubDate>
      <guid>https://xiang-wt.github.io/project/pytorch/</guid>
      <description>&lt;h2 id=&#34;-abstract&#34;&gt;üåç Abstract&lt;/h2&gt;
&lt;p&gt;This project investigates the &lt;strong&gt;cognitive level and payment willingness of residents&lt;/strong&gt; toward ecological compensation policies in the Yellow River Basin. Through large-scale fieldwork across 7 provinces and 28 cities, we collected and analyzed 2,617 valid questionnaires using &lt;strong&gt;CVM (Contingent Valuation Method)&lt;/strong&gt;, &lt;strong&gt;Probit regression&lt;/strong&gt;, and &lt;strong&gt;Structural Equation Modeling (SEM)&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;flex justify-center	&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;https://xiang-wt.github.io/files/diaoyan.jpg&#34; alt=&#34;Survey&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;Our findings revealed that while residents demonstrate clear ecological awareness and willingness to contribute financially, their understanding of compensation policies remains limited. Key influencing factors include satisfaction with the ecological environment, personal characteristics, and perceived governmental support.&lt;/p&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;flex justify-center	&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;https://xiang-wt.github.io/files/SEM.jpg&#34; alt=&#34;SEM&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;This work was awarded the &lt;strong&gt;National Second Prize&lt;/strong&gt; in the &lt;strong&gt;&amp;ldquo;Challenge Cup&amp;rdquo; Competition&lt;/strong&gt; , and has been compiled into a paper result (&lt;strong&gt;Manuscript&lt;/strong&gt;).&lt;/p&gt;
&lt;h2 id=&#34;-project-video&#34;&gt;üé• Project Video&lt;/h2&gt;
&lt;video controls width=&#34;100%&#34;&gt;
  &lt;source src=&#34;https://xiang-wt.github.io/files/intro.mp4&#34; type=&#34;video/mp4&#34;&gt;  
&lt;/video&gt;
&lt;h2 id=&#34;-key-contributions&#34;&gt;üí° Key Contributions&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Designed a comprehensive questionnaire based on CVM theory.&lt;/li&gt;
&lt;li&gt;Collected data through in-depth interviews, offline/online surveys (n=2617).&lt;/li&gt;
&lt;li&gt;Built statistical models (Probit, SEM) to quantify willingness-to-pay drivers.&lt;/li&gt;
&lt;li&gt;Proposed targeted ecological compensation policy recommendations.&lt;/li&gt;
&lt;li&gt;Recognized at national level award.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;-award&#34;&gt;üèÜ Award&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;National Second Prize&lt;/strong&gt; ¬∑ The 17th &amp;ldquo;Challenge Cup&amp;rdquo; National Undergraduate Extracurricular Academic and Technological Works Competition&lt;/p&gt;
&lt;h2 id=&#34;-project-duration&#34;&gt;üìÖ Project Duration&lt;/h2&gt;
&lt;p&gt;September 2020 ‚Äì March 2022&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>‚ú® Organized the Campus Glow Night Run</title>
      <link>https://xiang-wt.github.io/post/21.10.20/</link>
      <pubDate>Wed, 20 Oct 2021 00:00:00 +0000</pubDate>
      <guid>https://xiang-wt.github.io/post/21.10.20/</guid>
      <description>&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;flex justify-center	&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;https://xiang-wt.github.io/files/run.jpg&#34; alt=&#34;Run Photo&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;üéâ We successfully organized a large-scale campus event ‚Äî &lt;strong&gt;Glow Night Run&lt;/strong&gt;, which attracted a wide range of students from diverse backgrounds.&lt;/p&gt;
&lt;p&gt;The playground was full of glowing lights and joyful energy. Students wearing glow sticks and colorful accessories ran together under the night sky. Many international students joined as well, making it a vibrant celebration of health, culture, and connection.&lt;/p&gt;
&lt;p&gt;üí´ It was one of the most unforgettable moments in my university life, blending youth, energy, and cross-cultural communication.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>üëã Undergraduate Opening Ceremony 2019</title>
      <link>https://xiang-wt.github.io/post/19.9.28/</link>
      <pubDate>Sat, 28 Sep 2019 00:00:00 +0000</pubDate>
      <guid>https://xiang-wt.github.io/post/19.9.28/</guid>
      <description>&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;flex justify-center	&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;https://xiang-wt.github.io/files/kaixue.jpg&#34; alt=&#34;Kaixue Photo&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;üè´ On September 28, 2019, I attended the undergraduate opening ceremony as a freshman at Zhengzhou University.&lt;/p&gt;
&lt;p&gt;üéà Held in the university‚Äôs main stadium, the ceremony was solemn and grand. Surrounded by dazzling lights and an energetic crowd of fellow new students, I truly felt the honor and excitement of becoming a university student.&lt;/p&gt;
&lt;p&gt;‚ú® This evening marked the official beginning of my college journey. It was a moment of transformation ‚Äî stepping from high school into a new academic life ‚Äî and I was filled with motivation to learn, grow, and explore during the years to come.&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>
